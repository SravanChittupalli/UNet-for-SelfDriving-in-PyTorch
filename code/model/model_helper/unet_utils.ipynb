{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 2 parts: \n",
    "- Encoder\n",
    "- Decoder\n",
    "## Encoder\n",
    "- Encoder is a normal feature extractor.  \n",
    "- Encoder module can be broken down into subparts, we can call it as EncoderPart.  \n",
    "\n",
    "- ### EncoderPart\n",
    "    - Each EncoderPart is made up of 2 3x3 convolutions with RELU.  \n",
    "- ### Maxpool Layer\n",
    "    - After every EncoderPart we do 2x2 maxpool\n",
    "\n",
    "- ### UpConvolution Layer\n",
    "    - Before every DecoderPart 2x2 Upconvolution is performed\n",
    "- ### DecoderPart\n",
    "    - Each DecoderPart is made from concatinating from a previous layer having same number of channels and then 2 3x3 convolution followed by RELU\n",
    "\n",
    "- ### OutputLayer\n",
    "    - 1x1 conv applied to the last DecoderPart"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderPart(nn.Module):\n",
    "    def __init__(self, input_channel, output_channel):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channel, output_channel, kernel_size=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(output_channel, output_channel, kernel_size=3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.relu(x1)\n",
    "        x3 = self.conv2(x2)\n",
    "        x4 = self.relu(x3)\n",
    "        return x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 64, 568, 568])\n<bound method Module.parameters of EncoderPart(\n  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n  (relu): ReLU()\n  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n)>\n"
     ]
    }
   ],
   "source": [
    "encoder_part = EncoderPart(1, 64)\n",
    "\n",
    "## Test\n",
    "if TEST:\n",
    "    x = torch.randn(1, 1, 572, 572)\n",
    "    print(encoder_part(x).shape)\n",
    "    print(encoder_part.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Maxpool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.maxpool(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 64, 284, 284])\n"
     ]
    }
   ],
   "source": [
    "maxpool = Maxpool()\n",
    "\n",
    "if TEST:\n",
    "    x = torch.randn(1, 64, 568, 568)\n",
    "    print(maxpool(x).shape)"
   ]
  },
  {
   "source": [
    "## nn.ConvTranspose2d()\n",
    "Shape:\n",
    "- Input: (N,Cin,Hin,Win)\n",
    "- Output: (N,Cout,Hout,Wout)\n",
    "\n",
    "Where,\n",
    "- Hout=(Hin−1)×stride[0]−2×padding[0]+dilation[0]×(kernel_size[0]−1)+output_padding[0]+1\n",
    "- Wout=(Win−1)×stride[1]−2×padding[1]+dilation[1]×(kernel_size[1]−1)+output_padding[1]+1\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upconvolution(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super().__init__()\n",
    "        self.upconv = nn.ConvTranspose2d(input_channels, output_channels, kernel_size=2, stride=2) #input 28x28 out 56x56 || put 28 in above eqn\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.upconv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 512, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "upconv = Upconvolution(1024, 512)\n",
    "\n",
    "if TEST:\n",
    "    x = torch.randn(1, 1024, 28, 28)\n",
    "    print(upconv(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 1024, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "def concat(tensor_1, tensor_2):\n",
    "    '''\n",
    "    concatenate tensor_2 to tensor_1 \n",
    "    '''\n",
    "    dim_1 = tensor_1.shape[2]\n",
    "    dim_2 = tensor_2.shape[2]\n",
    "\n",
    "    part_to_remove = int((dim_2 - dim_1)/2)\n",
    "\n",
    "    cropped_tensor_2 = tensor_2[:, :, part_to_remove-1:(part_to_remove+dim_1-1), part_to_remove-1:(part_to_remove+dim_1-1)]\n",
    "\n",
    "    after_concat = torch.cat((tensor_1, cropped_tensor_2), dim=1) # dim=1 means concat along the channels \n",
    "\n",
    "    return after_concat\n",
    "\n",
    "if TEST:\n",
    "    print(concat(torch.randn(1,512,56,56), torch.randn(1,512,64,64)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderPart(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super().__init__()\n",
    "        self.conv_block = EncoderPart(input_channels, output_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 128, 100, 100])\n"
     ]
    }
   ],
   "source": [
    "decoder_part = DecoderPart(512, 128)\n",
    "\n",
    "if TEST:\n",
    "    x = torch.randn(1,512,104,104)\n",
    "    print(decoder_part(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputLayer(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super().__init__()\n",
    "        self.conv_layer = nn.Conv2d(input_channels, output_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 2, 388, 388])\n"
     ]
    }
   ],
   "source": [
    "output = OutputLayer(64, 2)\n",
    "\n",
    "if TEST:\n",
    "    x = torch.randn(1, 64, 388, 388)\n",
    "    print(output(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}